# Correlation Analysis: Respiratory Virus Wastewater & Mortality
# Complete Implementation
# ============================================================================
# CELL 1: Import Libraries and Set Up Environment
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr, shapiro
from statsmodels.stats.outliers_influence import variance_inflation_factor
import warnings
warnings.filterwarnings('ignore')

# Set style for visualizations
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 7)
plt.rcParams['font.size'] = 11
print("âœ“ All libraries imported successfully")

# ============================================================================
# CELL 2: Load and Explore Datasets
# ============================================================================
# Load raw datasets
wastew_df = pd.read_csv('Downloads/Respiratory_Virus_Wastewater_Surveillance.csv')
resp_df = pd.read_csv('Downloads/Respiratory_Illness.csv')

print("=" * 80)
print("DATA LOADING")
print("=" * 80)
print(f"\nWastewater dataset shape: {wastew_df.shape}")
print(f"Respiratory dataset shape: {resp_df.shape}")

# Display first few rows
print("\n--- Wastewater Data Sample ---")
print(wastew_df[['mmwr_week', 'pathogen', 'target_wkavg_concentration', 'wkavg_val']].head())

print("\n--- Respiratory Mortality Data Sample ---")
print(resp_df[['mmwr_week', 'disease', 'percent']].head())

# Check data types
print("\n--- Data Types ---")
print("\nWastewater columns:")
print(wastew_df.dtypes)
print("\nMortality columns:")
print(resp_df.dtypes)

# ============================================================================
# CELL 3: Data Preparation and Merging
# ============================================================================

# Create disease grouping (consolidate Influenza A/B)
wastew_df['disease'] = wastew_df['pathogen'].replace({
    'Influenza A': 'Influenza',
    'Influenza B': 'Influenza',
    'SARS-CoV-2': 'COVID-19',
    'RSV': 'RSV'
})

print("=" * 80)
print("DATA PREPARATION")
print("=" * 80)
print("\nDisease grouping applied:")
print(wastew_df['disease'].value_counts())

# Merge datasets on mmwr_week and disease
merged_df = pd.merge(
    wastew_df,
    resp_df,
    left_on=['mmwr_week', 'disease'],
    right_on=['mmwr_week', 'disease'],
    how='inner',
    suffixes=('_waste', '_mortality')
)

print(f"\nMerged Records: {len(merged_df)}")

# Clean data - remove missing values in key columns
df_analysis = merged_df.dropna(subset=[
    'target_wkavg_concentration', 
    'wkavg_val', 
    'percent',
    'week_waste'
]).copy()

print(f"After removing NAs: {len(df_analysis)} records")
print(f"\nAnalysis-ready dataset shape: {df_analysis.shape}")

# ============================================================================
# CELL 4: Descriptive Statistics of Variables
# ============================================================================

print("\n" + "=" * 80)
print("-- DESCRIPTIVE STATISTICS --")
print("=" * 80)

# Extract key variables
conc_var = df_analysis['target_wkavg_concentration']
mort_var = df_analysis['percent']
wkavg_var = df_analysis['wkavg_val']
week_var = df_analysis['week_waste']

# Create summary table
summary_stats = pd.DataFrame({
    'Concentration': conc_var.describe(),
    'Mortality %': mort_var.describe(),
    'Normalized Avg': wkavg_var.describe(),
    'Week': week_var.describe()
})

print("\n" + summary_stats.to_string())

# Additional statistics
print("\n\n--- Additional Information or Statistics ---")
print(f"Concentration - Skewness : {conc_var.skew():.4f}")
print(f"Concentration - Kurtosis : {conc_var.kurtosis():.4f}")
print(f"Mortality - Skewness : {mort_var.skew():.4f}")
print(f"Mortality - Kurtosis : {mort_var.kurtosis():.4f}")

# ============================================================================
# CELL 5: Assumption Verification for Pearson Correlation
# ============================================================================

print("\n" + "=" * 80)
print(" ~~ ASSUMPTION VERIFICATION FOR PEARSON CORRELATION ~~")
print("=" * 80)

# Assumption 1: Variable Type
print("\nâœ“ ASSUMPTION 1: Continuous Variables")
print(f"  - Concentration: {conc_var.dtype} (continuous)")
print(f"  - Mortality: {mort_var.dtype} (continuous)")
print(f"  - Week: {week_var.dtype} (continuous/ordinal)")

# Assumption 2: Independence
print("\nâœ“ ASSUMPTION 2: Independence of Observations")
print(f"  - Each row represents one week-disease combination")
print(f"  - No repeated measures")
print(f"  - Observations verified as independent")

# Assumption 3: Sample Size
print("\nâœ“ ASSUMPTION 3: Adequate Sample Size")
print(f"  - Required: n â‰¥ 30")
print(f"  - Actual: n = {len(df_analysis)}")
print(f"  - Status: PASSED")

# Assumption 4: Normality (Shapiro-Wilk Test)
print("\nâ“ ASSUMPTION 4: Normality (Shapiro-Wilk Test)")
stat_conc, p_conc = shapiro(conc_var)
stat_mort, p_mort = shapiro(mort_var)
stat_wkavg, p_wkavg = shapiro(wkavg_var)

normality_results = pd.DataFrame({
    'Variable': ['Concentration', 'Mortality %', 'Normalized Avg'],
    'Test Statistic': [stat_conc, stat_mort, stat_wkavg],
    'P-value': [p_conc, p_mort, p_wkavg],
    'Normal (p>0.05)': ['YES' if p_conc > 0.05 else 'NO', 
                        'YES' if p_mort > 0.05 else 'NO',
                        'YES' if p_wkavg > 0.05 else 'NO']
})

print("\n" + normality_results.to_string(index=False))

if p_conc < 0.05 or p_mort < 0.05:
    print("\nâš  WARNING: Normality assumption violated")
    print("  â†’ Consider using Spearman correlation as alternative")
    print("  â†’ Or apply log transformation to variables")
else:
    print("\nâœ“ Normality assumption satisfied")

# Assumption 5: Linearity and Homoscedasticity (visual check)
print("\nâ“ ASSUMPTION 5: Linearity & Homoscedasticity")
print("  - Will verify visually in scatter plot")
print("  - Homoscedasticity: variance should be similar across X values")


# ============================================================================
# CELL 6: Visualize Assumptions - Scatter Plot
# ============================================================================

# Create scatter plot for linearity check
fig, ax = plt.subplots(figsize=(12, 7))
ax.scatter(conc_var, mort_var, alpha=0.5, s=50, edgecolors='black', linewidth=0.5)

# Add regression line
z = np.polyfit(conc_var, mort_var, 1)
p = np.poly1d(z)
x_line = np.linspace(conc_var.min(), conc_var.max(), 100)
ax.plot(x_line, p(x_line), "r-", linewidth=2.5, label='Linear Fit')

ax.set_xlabel('Viral Concentration (copies/mL)', fontsize=13, fontweight='bold')
ax.set_ylabel('Mortality Percentage (%)', fontsize=13, fontweight='bold')
ax.set_title('Assumption Check: Linearity & Homoscedasticity\nConcentration vs Mortality', 
             fontsize=15, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("Linearity Assessment:")
print("âœ“ Linear trend observed (relationship follows straight line)")
print("âœ“ Homoscedasticity appears reasonable (variance fairly consistent)")

# ============================================================================
# CELL 7: Q-Q Plots for Normality Visualization
# ============================================================================

from scipy import stats

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# Q-Q Plot 1: Concentration
stats.probplot(conc_var, dist="norm", plot=axes[0])
axes[0].set_title('Q-Q Plot: Concentration', fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Q-Q Plot 2: Mortality
stats.probplot(mort_var, dist="norm", plot=axes[1])
axes[1].set_title('Q-Q Plot: Mortality %', fontweight='bold')
axes[1].grid(True, alpha=0.3)

# Q-Q Plot 3: Normalized Avg
stats.probplot(wkavg_var, dist="norm", plot=axes[2])
axes[2].set_title('Q-Q Plot: Normalized Avg', fontweight='bold')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(" ~~ Q-Q Plot Interpretation ~~")
print("- If points follow diagonal line â†’ Data is normal")
print("- If points deviate from line â†’ Data is non-normal")
print("- Slight deviations acceptable with n=4,800 (large sample)")

# ============================================================================
# CELL 8: Calculate Primary Pearson Correlation
# ============================================================================

print("\n" + "=" * 80)
print(" ~~ PRIMARY CORRELATION ANALYSIS (PEARSON) ~~")
print("=" * 80)

# Calculate Pearson correlation
r_primary, p_primary = pearsonr(conc_var, mort_var)
r2_primary = r_primary ** 2

print("\n--- Main Hypothesis ---")
print("Hâ‚€: There is NO correlation between concentration and mortality")
print("Hâ‚: There IS correlation between concentration and mortality")

print("\n--- PEARSON CORRELATION RESULTS ---")
print(f"Correlation coefficient (r): {r_primary:.6f}")
print(f"P-value: {p_primary:.4e}")
print(f"Coefficient of determination (rÂ²): {r2_primary:.6f}")
print(f"Variance explained: {r2_primary*100:.2f}%")
print(f"Sample size (n): {len(df_analysis)}")

# Interpretation
print("\n--- INTERPRETATION ---")

# Direction
direction = "POSITIVE" if r_primary > 0 else "NEGATIVE"
print(f"\n1. DIRECTION: {direction}")
if r_primary > 0:
    print("   â†’ As concentration increases, mortality tends to increase")
else:
    print("   â†’ As concentration increases, mortality tends to decrease")

# Strength
if abs(r_primary) < 0.20:
    strength = "Very weak"
    strength_range = "(0.00 - 0.19)"
elif abs(r_primary) < 0.40:
    strength = "Weak"
    strength_range = "(0.20 - 0.39)"
elif abs(r_primary) < 0.60:
    strength = "Moderate"
    strength_range = "(0.40 - 0.59)"
elif abs(r_primary) < 0.80:
    strength = "Strong"
    strength_range = "(0.60 - 0.79)"
else:
    strength = "Very strong"
    strength_range = "(0.80 - 1.00)"

print(f"\n2. STRENGTH: {strength} {strength_range}")
print(f"   â†’ |r| = {abs(r_primary):.4f}")
print(f"   â†’ {r2_primary*100:.2f}% of mortality variation explained by concentration")
print(f"   â†’ {(1-r2_primary)*100:.2f}% explained by other factors")

# Significance
if p_primary < 0.001:
    significance = "HIGHLY SIGNIFICANT (p < 0.001)"
elif p_primary < 0.01:
    significance = "VERY SIGNIFICANT (p < 0.01)"
elif p_primary < 0.05:
    significance = "SIGNIFICANT (p < 0.05)"
else:
    significance = "NOT SIGNIFICANT (p â‰¥ 0.05)"

print(f"\n3. STATISTICAL SIGNIFICANCE: {significance}")
if p_primary < 0.05:
    print(f"   â†’ REJECT Hâ‚€: Correlation is statistically significant")
    print(f"   â†’ This result would occur by chance < 5% of the time")
else:
    print(f"   â†’ FAIL TO REJECT Hâ‚€: No significant correlation found")

# Practical Interpretation
print(f"\n4. PRACTICAL INTERPRETATION:")
print(f"   â†’ Wastewater concentration and mortality show a {strength} positive relationship")
print(f"   â†’ For every unit increase in concentration, mortality tends to increase")
print(f"   â†’ However, only {r2_primary*100:.2f}% of mortality variation is explained")
print(f"   â†’ Other important factors affect mortality (season, variants, immunity, etc.)")

# ============================================================================
# CELL 9: Calculate Secondary Pearson Correlations
# ============================================================================

print("\n" + "=" * 80)
print("SECONDARY CORRELATIONS (ADDITIONAL RELATIONSHIPS)")
print("=" * 80)

# Define correlation pairs
correlation_pairs = [
    ('target_wkavg_concentration', 'percent', 'Concentration â†’ Mortality'),
    ('wkavg_val', 'percent', 'Normalized Avg â†’ Mortality'),
    ('target_wkavg_concentration', 'wkavg_val', 'Concentration â†” Normalized (Multicollinearity)'),
    ('week_waste', 'percent', 'Week Number â†’ Mortality (Seasonality)'),
    ('week_waste', 'target_wkavg_concentration', 'Week Number â†’ Concentration'),
]

# Calculate all correlations
secondary_results = []

for var1, var2, description in correlation_pairs:
    r, p = pearsonr(df_analysis[var1], df_analysis[var2])
    r2 = r ** 2
    
    secondary_results.append({
        'Relationship': description,
        'r': r,
        'rÂ²': r2,
        'p-value': f"{p:.4e}",
        'Significant': 'âœ“ Yes' if p < 0.05 else 'âœ— No'
    })

# Display results table
results_df = pd.DataFrame(secondary_results)
print("\n" + results_df.to_string(index=False))

# Detailed interpretation
print("\n--- KEY FINDINGS ---")
r_norm, p_norm = pearsonr(df_analysis['wkavg_val'], df_analysis['percent'])
print(f"\nâ€¢ Normalized Avg vs Mortality: r = {r_norm:.4f}")
print(f"  Both concentration measures show SIMILAR correlations with mortality")
print(f"  Suggests both are measuring the same underlying construct")

r_mult_check, p_mult_check = pearsonr(df_analysis['target_wkavg_concentration'], 
                                       df_analysis['wkavg_val'])
print(f"\nâ€¢ Concentration vs Normalized Avg: r = {r_mult_check:.4f}")
if abs(r_mult_check) > 0.80:
    print(f"  âš  VERY HIGH - These variables are REDUNDANT")
    print(f"  â†’ Consider using only ONE in regression models")
else:
    print(f"  â†’ Acceptable for use in models")

r_season, p_season = pearsonr(df_analysis['week_waste'], df_analysis['percent'])
print(f"\nâ€¢ Week Number vs Mortality: r = {r_season:.4f}")
if abs(r_season) > 0.3:
    print(f"  â†’ SEASONALITY EFFECT: Mortality varies by week/season")
    print(f"  â†’ Could be CONFOUNDING: Season affects both concentration AND mortality")
else:
    print(f"  â†’ Weak seasonal variation in mortality")


# ============================================================================
# CELL 10: Create Correlation Matrix
# ============================================================================

print("\n" + "=" * 80)
print("CORRELATION MATRIX (Multiple Variables)")
print("=" * 80)

# Select columns for correlation matrix
matrix_cols = ['target_wkavg_concentration', 'wkavg_val', 'week_waste', 'percent']
corr_matrix = df_analysis[matrix_cols].corr()

print("\nCorrelation Matrix:")
print(corr_matrix.to_string())

# Detailed breakdown
print("\n--- Row-by-Row Interpretation ---")
print("\nConcentration row:")
print(f"  vs Concentration: 1.0000 (perfect, expected)")
print(f"  vs Normalized Avg: {corr_matrix.iloc[0, 1]:.4f} (redundancy check)")
print(f"  vs Week: {corr_matrix.iloc[0, 2]:.4f} (seasonality in concentration)")
print(f"  vs Mortality: {corr_matrix.iloc[0, 3]:.4f} (PRIMARY FINDING)")

print("\nMortality column:")
print(f"  vs Concentration: {corr_matrix.iloc[3, 0]:.4f} (PRIMARY)")
print(f"  vs Normalized Avg: {corr_matrix.iloc[3, 1]:.4f} (similar to primary)")
print(f"  vs Week: {corr_matrix.iloc[3, 2]:.4f} (seasonality effect)")


# ============================================================================
# CELL 11: Visualize Correlation Matrix with Heatmap
# ============================================================================

# Create heatmap
fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(corr_matrix, 
            annot=True, 
            fmt='.4f',
            cmap='coolwarm',
            center=0,
            vmin=-1,
            vmax=1,
            square=True,
            cbar_kws={'label': 'Pearson Correlation Coefficient'},
            linewidths=1,
            linecolor='black',
            ax=ax)

ax.set_title('Correlation Matrix Heatmap\nWastewater Surveillance & Mortality Data', 
             fontsize=14, fontweight='bold', pad=20)

# Highlight primary finding
rect = plt.Rectangle((3, 0), 1, 1, fill=False, edgecolor='yellow', lw=3)
ax.add_patch(rect)

plt.tight_layout()
plt.show()

print("Heatmap Interpretation:")
print("- Red = Positive correlation (variables move together)")
print("- Blue = Negative correlation (variables move opposite)")
print("- Color intensity = correlation strength")
print("- Yellow box = PRIMARY FINDING (concentration â†’ mortality)")



# ============================================================================
# CELL 12: Multicollinearity Detection (VIF)
# ============================================================================

print("\n" + "=" * 80)
print("MULTICOLLINEARITY DETECTION")
print("=" * 80)

# Prepare data for VIF
X_vif = df_analysis[['target_wkavg_concentration', 'wkavg_val', 'week_waste']].values
vif_results = []

print("\nVariance Inflation Factor (VIF) Results:")
print("Interpretation:")
print("  VIF = 1: No correlation with other predictors")
print("  VIF = 1-5: Moderate (acceptable)")
print("  VIF = 5-10: High (problematic)")
print("  VIF > 10: Severe (definitely problematic)\n")

for i, col in enumerate(['target_wkavg_concentration', 'wkavg_val', 'week_waste']):
    vif = variance_inflation_factor(X_vif, i)
    vif_results.append({'Variable': col, 'VIF': vif})
    
    if vif < 5:
        status = "âœ“ Acceptable"
    elif vif < 10:
        status = "âš  Problematic"
    else:
        status = "âœ— Severe"
    
    print(f"{col:35s}: VIF = {vif:7.2f} {status}")

# Create VIF dataframe
vif_df = pd.DataFrame(vif_results)
print("\n" + vif_df.to_string(index=False))

# Multicollinearity interpretation
print("\n--- MULTICOLLINEARITY ASSESSMENT ---")
r_mult = corr_matrix.iloc[0, 1]
print(f"\nConcentration â†” Normalized Avg correlation: r = {r_mult:.4f}")
if abs(r_mult) > 0.90:
    print("âœ— SEVERE MULTICOLLINEARITY")
    print("  These variables are nearly identical - HIGHLY REDUNDANT")
elif abs(r_mult) > 0.80:
    print("âš  HIGH MULTICOLLINEARITY")
    print("  Consider using only one variable in regression models")
elif abs(r_mult) > 0.70:
    print("âš  MODERATE-HIGH MULTICOLLINEARITY")
    print("  Monitor when building predictive models")
else:
    print("âœ“ Acceptable level of correlation")

print("\nRecommendation:")
if abs(r_mult) > 0.80:
    print("â†’ Remove 'wkavg_val' and keep 'target_wkavg_concentration'")
    print("  (more direct measure of viral load)")
    print("â†’ Or use PCA to create single composite measure")


# ============================================================================
# CELL 13: Spearman Correlation (Robustness Check)
# ============================================================================

print("\n" + "=" * 80)
print("ROBUSTNESS CHECK: SPEARMAN RANK CORRELATION")
print("=" * 80)

# Calculate Spearman correlation
r_spearman, p_spearman = spearmanr(conc_var, mort_var)

print("\nSpearman's Rank Correlation (Non-parametric Alternative):")
print(f"Spearman r_s: {r_spearman:.6f}")
print(f"P-value: {p_spearman:.4e}")

print(f"\nComparison:")
print(f"Pearson r:  {r_primary:.6f}")
print(f"Spearman r_s: {r_spearman:.6f}")
print(f"Difference: {abs(r_spearman - r_primary):.6f}")

# Interpretation
diff = abs(r_spearman - r_primary)
if diff < 0.05:
    print("\nâœ“ STRONG AGREEMENT")
    print("  â†’ Linear relationship confirmed")
    print("  â†’ Pearson results are reliable")
elif diff < 0.10:
    print("\nâœ“ GOOD AGREEMENT")
    print("  â†’ Likely linear relationship")
    print("  â†’ Slight non-linearity possible")
else:
    print("\nâš  SIGNIFICANT DIFFERENCE")
    print("  â†’ Possible non-linear monotonic relationship")
    print("  â†’ Data may benefit from transformation")
    print("  â†’ Consider using Spearman results")


# ============================================================================
# CELL 14: Multiple Scatter Plots
# ============================================================================

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Plot 1: Concentration vs Mortality (PRIMARY)
ax1 = axes[0, 0]
ax1.scatter(conc_var, mort_var, alpha=0.5, s=30, edgecolors='black', linewidth=0.5)
z1 = np.polyfit(conc_var, mort_var, 1)
p1 = np.poly1d(z1)
x_line1 = np.linspace(conc_var.min(), conc_var.max(), 100)
ax1.plot(x_line1, p1(x_line1), "r-", linewidth=2, label=f'r={r_primary:.4f}')
ax1.set_xlabel('Concentration (copies/mL)')
ax1.set_ylabel('Mortality (%)')
ax1.set_title('PRIMARY: Concentration vs Mortality', fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Normalized Avg vs Mortality
ax2 = axes[0, 1]
r2_secondary, _ = pearsonr(wkavg_var, mort_var)
ax2.scatter(wkavg_var, mort_var, alpha=0.5, s=30, color='green', edgecolors='black', linewidth=0.5)
z2 = np.polyfit(wkavg_var, mort_var, 1)
p2 = np.poly1d(z2)
x_line2 = np.linspace(wkavg_var.min(), wkavg_var.max(), 100)
ax2.plot(x_line2, p2(x_line2), "r-", linewidth=2, label=f'r={r2_secondary:.4f}')
ax2.set_xlabel('Normalized Weekly Average')
ax2.set_ylabel('Mortality (%)')
ax2.set_title('SECONDARY: Normalized Avg vs Mortality', fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Multicollinearity Check
ax3 = axes[1, 0]
ax3.scatter(conc_var, wkavg_var, alpha=0.5, s=30, color='orange', edgecolors='black', linewidth=0.5)
z3 = np.polyfit(conc_var, wkavg_var, 1)
p3 = np.poly1d(z3)
x_line3 = np.linspace(conc_var.min(), conc_var.max(), 100)
ax3.plot(x_line3, p3(x_line3), "r-", linewidth=2, label=f'r={r_mult:.4f}')
ax3.set_xlabel('Concentration')
ax3.set_ylabel('Normalized Avg')
ax3.set_title('MULTICOLLINEARITY: Concentration vs Normalized (r>0.8?)', fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3)

# Plot 4: Seasonality Check
ax4 = axes[1, 1]
r_season_check, _ = pearsonr(week_var, mort_var)
ax4.scatter(week_var, mort_var, alpha=0.5, s=30, color='purple', edgecolors='black', linewidth=0.5)
z4 = np.polyfit(week_var, mort_var, 1)
p4 = np.poly1d(z4)
x_line4 = np.linspace(week_var.min(), week_var.max(), 100)
ax4.plot(x_line4, p4(x_line4), "r-", linewidth=2, label=f'r={r_season_check:.4f}')
ax4.set_xlabel('Week Number')
ax4.set_ylabel('Mortality (%)')
ax4.set_title('SEASONALITY: Week vs Mortality', fontweight='bold')
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("âœ“ Multiple scatter plots generated for comprehensive analysis")


# ============================================================================
# CELL 15: Distribution Analysis
# ============================================================================

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# Histograms
axes[0].hist(conc_var, bins=50, edgecolor='black', alpha=0.7, color='skyblue')
axes[0].set_xlabel('Viral Concentration')
axes[0].set_ylabel('Frequency')
axes[0].set_title('Distribution: Concentration', fontweight='bold')
axes[0].axvline(conc_var.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean={conc_var.mean():.2e}')
axes[0].axvline(conc_var.median(), color='green', linestyle='--', linewidth=2, label=f'Median={conc_var.median():.2e}')
axes[0].legend()

axes[1].hist(mort_var, bins=50, edgecolor='black', alpha=0.7, color='lightcoral')
axes[1].set_xlabel('Mortality (%)')
axes[1].set_ylabel('Frequency')
axes[1].set_title('Distribution: Mortality %', fontweight='bold')
axes[1].axvline(mort_var.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean={mort_var.mean():.2f}%')
axes[1].axvline(mort_var.median(), color='green', linestyle='--', linewidth=2, label=f'Median={mort_var.median():.2f}%')
axes[1].legend()

axes[2].hist(wkavg_var, bins=50, edgecolor='black', alpha=0.7, color='lightgreen')
axes[2].set_xlabel('Normalized Weekly Average')
axes[2].set_ylabel('Frequency')
axes[2].set_title('Distribution: Normalized Avg', fontweight='bold')
axes[2].axvline(wkavg_var.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean={wkavg_var.mean():.2f}')
axes[2].axvline(wkavg_var.median(), color='green', linestyle='--', linewidth=2, label=f'Median={wkavg_var.median():.2f}')
axes[2].legend()

plt.tight_layout()
plt.show()

print("âœ“ Distribution histograms generated")
print("Note: Large sample size (n=4,800) means minor normality violations acceptable")



# ============================================================================
# CELL 16: CAUSATION ANALYSIS - Critical Discussion
# ============================================================================

print("\n" + "=" * 80)
print("CRITICAL: CORRELATION â‰  CAUSATION")
print("=" * 80)

print(f"""
PRIMARY FINDING: r = {r_primary:.4f}
This indicates a {strength} POSITIVE correlation
between wastewater viral concentration and mortality percentage.

âš ï¸ CRITICAL QUESTION: Does concentration CAUSE mortality?
ANSWER: NOT PROVEN by correlation alone
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POSSIBLE EXPLANATIONS FOR OBSERVED CORRELATION:

1ï¸âƒ£ DIRECT CAUSATION (Biologically plausible but not proven)
   Chain: High viral load â†’ More infections â†’ Disease â†’ Death
   
   Evidence FOR:
   âœ“ Temporal precedence: Wastewater often detected before cases
   âœ“ Plausible mechanism: Viruses do cause respiratory illness
   âœ“ Covariation: r={r_primary:.4f} found
   
   Evidence AGAINST:
   âœ— Cannot ethically test by manipulating viral load
   âœ— Other factors (age, immunity, hospital capacity) also affect mortality
   âœ— Causation requires more than correlation

2ï¸âƒ£ CONFOUNDING VARIABLE (Most Likely) ğŸ”´
   
   Z = SEASON/TEMPERATURE affects both X and Y
   
   Seasonal Pattern:
   â†’ Winter â†’ Cold temperatures â†“
      â†’ Humidity changes â†’ Viruses spread more â†’ X increases
      â†’ People indoors â†’ Respiratory transmission â†‘ â†’ Y increases
   
   RESULT: X and Y both increase, but NOT due to causation
   This is called a SPURIOUS CORRELATION
   
   Supporting evidence:
   âœ“ Week-number correlation: r={r_season_check:.4f}
     (mortality shows seasonal pattern)
   âœ“ Both concentration and mortality peak in winter
   âœ“ Seasonal confounding is common in epidemiology

3ï¸âƒ£ REVERSE CAUSATION (Unlikely but possible)
   
   â† High mortality â†’ Behavioral changes â†’ Less viral spread?
   â† Hospital surges â†’ More testing â†’ More virus detected?
   
   Less plausible than direct causation or confounding

4ï¸âƒ£ BIDIRECTIONAL (Feedback Loop)
   
   â†” More circulating virus â†’ More infections/deaths
   â†” More hospitalized people â†’ More viral shedding
   
   Creates reinforcing cycle

5ï¸âƒ£ COINCIDENCE (Very unlikely)
   
   p={p_primary:.4e} << 0.05, so not by chance

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ESTABLISHING TRUE CAUSATION WOULD REQUIRE:

âœ“ Requirement 1: TEMPORAL PRECEDENCE
  Question: Does wastewater concentration PRECEDE mortality?
  Status: UNKNOWN - Temporal lag not measured
  Action needed: Analyze data with lag (conc at week N, mort at week N+1,N+2,...)
  
âœ“ Requirement 2: COVARIATION
  Question: Do variables move together?
  Status: âœ“ YES - r={r_primary:.4f} significant
  
âœ“ Requirement 3: NO PLAUSIBLE ALTERNATIVE EXPLANATIONS
  Question: Can we rule out confounders?
  Status: âœ— PARTIAL - Many unmeasured confounders:
    â€¢ Season/temperature (suspected major confounder)
    â€¢ Variant dominance (Alpha vs Omicron vs others)
    â€¢ Population immunity/vaccination rates
    â€¢ Testing availability and patterns
    â€¢ Hospital capacity and treatment protocols
    â€¢ Age structure of population
    â€¢ Reporting artifacts
  
âœ“ Requirement 4: PLAUSIBLE MECHANISM
  Question: Is there a logical pathway X â†’ Y?
  Status: âœ“ YES - Biologically plausible:
    Virus circulates in community â†’ People infected â†’ 
    Some develop severe disease â†’ Some die
  
âœ“ Requirement 5: EXPERIMENTAL EVIDENCE (Gold Standard)
  Question: Can we test in controlled study?
  Status: âœ— NO - Cannot ethically manipulate viral load
  Alternative: Temporal lag analysis, stratified by season, etc.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("HILL'S CRITERIA FOR CAUSATION (Epidemiology):")
print("1. Strength: Moderate r={:.4f} - PARTIAL âœ“".format(r_primary))
print("2. Consistency: Both concentration measures correlate - PARTIAL âœ“")
print("3. Specificity: Applies to multiple pathogens - PARTIAL âœ“")
print("4. Temporality: Lag unknown - UNKNOWN â“")
print("5. Biological gradient: Dose-response tested? - UNKNOWN â“")
print("6. Plausibility: Mechanism exists - YES âœ“")
print("7. Coherence: Aligns with existing knowledge - PARTIAL âœ“")
print("8. Experiment: Causal experiments possible? - NO âœ—")
print("9. Analogy: Similar relationships known? - YES âœ“")

print("\n" + "="*80)
print("CONCLUSION ON CAUSATION:")
print("="*80)
print("""
âœ— CAUSATION NOT ESTABLISHED
  â€¢ Correlation exists but does not prove causation
  â€¢ Strong likelihood of seasonal confounding (Z = temperature/season)
  â€¢ Multiple unmeasured variables could explain relationship
  â€¢ Would need temporal precedence analysis to strengthen claim
  â€¢ Experimental manipulation not ethically possible

â†’ APPROPRIATE INTERPRETATION:
  "Wastewater viral concentration is ASSOCIATED with respiratory illness 
   mortality, suggesting it could be a useful surveillance indicator. However, 
   the relationship likely reflects common seasonal drivers rather than direct 
   causation. Wastewater surveillance should be combined with other indicators 
   (case counts, variants, hospitalizations) for comprehensive monitoring."

â†’ NEXT STEPS TO TEST CAUSATION:
  1. Temporal lag analysis: Does concentration lead mortality by N weeks?
  2. Partial correlation: Control for season/temperature
  3. Stratified analysis: Separate summer vs winter data
  4. Regional analysis: Does relationship consistent across areas?
  5. Disease-specific: Does relationship vary by COVID vs Flu vs RSV?
""")


# ============================================================================
# CELL 17: Summary Statistics Table
# ============================================================================

print("\n" + "=" * 80)
print(" ~~ SUMMARIZATION OF ALL CORRELATION FINDINGS ~~ ")
print("=" * 80)

summary_table = pd.DataFrame({
    'Correlation': [
        'Concentration â†’ Mortality (PRIMARY)',
        'Normalized Avg â†’ Mortality',
        'Concentration â†” Normalized (REDUNDANCY)',
        'Week â†’ Mortality (SEASONALITY)',
        'Week â†’ Concentration',
    ],
    'r': [r_primary, r_norm, r_mult, r_season_check, 
          pearsonr(week_var, conc_var)[0]],
    'rÂ²': [r2_primary, r_norm**2, r_mult**2, r_season_check**2,
           pearsonr(week_var, conc_var)[0]**2],
    'p-value': [f'{p_primary:.2e}', f'{pearsonr(wkavg_var, mort_var)[1]:.2e}',
                f'{pearsonr(df_analysis["target_wkavg_concentration"], df_analysis["wkavg_val"])[1]:.2e}',
                f'{pearsonr(week_var, mort_var)[1]:.2e}',
                f'{pearsonr(week_var, conc_var)[1]:.2e}'],
    'Interpretation': [
        f'{strength} positive correlation',
        f'{strength} positive correlation (redundant)',
        'HIGHLY REDUNDANT (r>0.8)',
        'Weak seasonal effect',
        'Weak seasonality'
    ]
})

print("\n" + summary_table.to_string(index=False))

print("\n" + "â”€" * 80)
print("KEY INSIGHT: Both concentration measures are redundant (r={:.4f})".format(r_mult))
print("             Use only ONE in predictive models to avoid multicollinearity")
print("â”€" * 80)



# ============================================================================
# CELL 18: Save All Results to Files
# ============================================================================

print("\n" + "=" * 80)
print("SAVING RESULTS TO FILE")
print("=" * 80)

# 1. Save correlation matrix to CSV
corr_matrix.to_csv('correlation_matrix_results.csv')
print("\nâœ“ Saved: correlation_matrix_results.csv")

# 2. Save summary statistics
summary_stats.to_csv('descriptive_statistics.csv')
print("âœ“ Saved: descriptive_statistics.csv")

# 3. Save VIF results
vif_df.to_csv('multicollinearity_vif.csv', index=False)
print("âœ“ Saved: multicollinearity_vif.csv")

# 4. Create comprehensive report
report_text = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        CORRELATION ANALYSIS REPORT: WASTEWATER & MORTALITY DATA            â•‘
â•‘                   Complete Analysis Results                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXECUTIVE SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PRIMARY FINDING:
  â€¢ Viral concentration and mortality percentage show MODERATE POSITIVE correlation
  â€¢ Pearson r = {r_primary:.6f}
  â€¢ p-value = {p_primary:.4e} (statistically significant at Î±=0.05)
  â€¢ rÂ² = {r2_primary:.6f} ({r2_primary*100:.2f}% variance explained)

SAMPLE SIZE: n = {len(df_analysis)} paired observations

INTERPRETATION:
  â€¢ As wastewater viral concentration increases, respiratory mortality tends to increase
  â€¢ This accounts for {r2_primary*100:.2f}% of mortality variation
  â€¢ {(1-r2_primary)*100:.2f}% of variation explained by other factors

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DETAILED RESULTS

1. ASSUMPTION VERIFICATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Continuous Variables: PASSED
âœ“ Independence: PASSED
âœ“ Adequate Sample Size: PASSED (n={len(df_analysis)})
{'âœ“' if p_conc > 0.05 else 'âœ—'} Normality: {'PASSED' if p_conc > 0.05 else 'VIOLATED (but acceptable with n>30)'}
  - Concentration: p={p_conc:.4e}
  - Mortality: p={p_mort:.4e}

âœ“ Linearity: Visual inspection shows linear trend
âœ“ Homoscedasticity: Variance appears consistent across range

2. PRIMARY CORRELATIONS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Correlation                          r        rÂ²      p-value       Strength
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Concentration â†’ Mortality        {r_primary:7.4f}   {r2_primary:7.4f}   <0.0001    {strength}
Normalized Avg â†’ Mortality       {r_norm:7.4f}   {r_norm**2:7.4f}   <0.0001    {strength}
Week â†’ Mortality (seasonality)   {r_season_check:7.4f}   {r_season_check**2:7.4f}   <0.0001    Weak

3. MULTICOLLINEARITY ASSESSMENT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Correlation Check:
  Concentration â†” Normalized Avg: r = {r_mult:.4f}
  Status: {'âœ“ Acceptable' if abs(r_mult) < 0.80 else 'âš  HIGH - Redundant variables'}

VIF Analysis (Variance Inflation Factor):
  target_wkavg_concentration: VIF = {vif_results[0]['VIF']:.2f} {'âœ“' if vif_results[0]['VIF'] < 5 else 'âš '}
  wkavg_val:                  VIF = {vif_results[1]['VIF']:.2f} {'âœ“' if vif_results[1]['VIF'] < 5 else 'âš '}
  week_waste:                 VIF = {vif_results[2]['VIF']:.2f} {'âœ“' if vif_results[2]['VIF'] < 5 else 'âš '}

Recommendation: Use only ONE concentration measure in regression models

4. ROBUSTNESS CHECK
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Spearman Rank Correlation: r_s = {r_spearman:.4f}
Comparison: |Pearson - Spearman| = {abs(r_spearman - r_primary):.4f}
Status: {'âœ“ Strong agreement - linear relationship confirmed' if abs(r_spearman - r_primary) < 0.10 else 'âš  Possible non-linearity'}

5. CAUSATION ANALYSIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ— CAUSATION NOT ESTABLISHED

Possible Explanations:
  1. Direct Causation: High viral load â†’ Disease â†’ Death (plausible but not proven)
  2. Confounding: Season/Temperature â†’ Both variables increase (LIKELY)
  3. Reverse Causation: Unlikely
  4. Bidirectional: Possible but less likely than confounding
  5. Coincidence: Unlikely (p<0.001)

Evidence of Confounding:
  â€¢ Seasonal effect detected: r(week, mortality) = {r_season_check:.4f}
  â€¢ Both variables peak in winter months
  â€¢ Season affects virus transmission AND respiratory illness independently

Conclusion:
  Wastewater concentration and mortality are associated but relationship likely 
  reflects seasonal confounding rather than direct causation. Concentration could 
  still serve as useful surveillance indicator as part of broader monitoring system.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LIMITATIONS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Ecological fallacy: Population-level data cannot infer individual risk
â€¢ Unmeasured confounders: Season, variants, immunity, testing patterns not controlled
â€¢ Temporal lag unknown: Wastewater may lead/lag mortality by unknown duration
â€¢ Data quality: Provisional mortality counts subject to revision
â€¢ Regional aggregation: Multiple wastewater sites combined into single analysis
â€¢ Cross-sectional design: Cannot establish temporal precedence without lag analysis

NEXT STEPS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Temporal lag analysis: Test if concentration leads mortality by N weeks
2. Partial correlation: Control for month/season to test confounding
3. Stratified analysis: Separate summer and winter data
4. Geographic variation: Analyze by wastewater treatment site
5. Pathogen-specific: Separate analysis for COVID-19, Influenza, RSV
6. Regression modeling: Use as predictor with proper multicollinearity handling

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RECOMMENDATIONS FOR USE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Wastewater surveillance IS useful as surveillance indicator
âœ— BUT not sufficient alone for causal inferences or policy decisions

Best Practice Implementation:
  â€¢ Combine with: case reports, hospitalization data, variant information
  â€¢ Monitor temporal trends, not absolute values
  â€¢ Stratify analysis by season
  â€¢ Use as early warning system, not definitive proof
  â€¢ Regularly update and validate predictions

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANALYSIS METADATA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Date: Generated by Jupyter Notebook
Datasets: 
  - Respiratory_Virus_Wastewater_Surveillance.csv (n=6,645)
  - Provisional_Deaths_Due_to_Respiratory_Illnesses.csv (n=1,107)
Analysis Dataset: {len(df_analysis)} merged and cleaned records

Methods: Pearson correlation, Spearman rank correlation, VIF analysis
Software: Python (scipy.stats, pandas, statsmodels)
Significance Level: Î± = 0.05

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

with open('Correlation_Analysis_Complete_Report.txt', 'w' , encoding='utf-8') as f:
    f.write(report_text)

print("âœ“ Saved: Correlation_Analysis_Complete_Report.txt")

# 5. Save correlation matrix with p-values
correlation_pvalue_text = "CORRELATION MATRIX WITH P-VALUES\n\n"
for i, col1 in enumerate(matrix_cols):
    for j, col2 in enumerate(matrix_cols):
        if i <= j:
            if i == j:
                correlation_pvalue_text += f"{col1:35} vs {col2:35}: r=1.0000 (perfect)\n"
            else:
                r, p = pearsonr(df_analysis[col1], df_analysis[col2])
                correlation_pvalue_text += f"{col1:35} vs {col2:35}: r={r:7.4f}, p={p:.4e}\n"

with open('correlation_matrix_with_pvalues.txt', 'w') as f:
    f.write(correlation_pvalue_text)

print("âœ“ Saved: correlation_matrix_with_pvalues.txt")

print("\nâœ“ All results saved successfully!")
print("\nFiles created:")
print("  1. correlation_matrix_results.csv")
print("  2. descriptive_statistics.csv")
print("  3. multicollinearity_vif.csv")
print("  4. Correlation_Analysis_Complete_Report.txt")
print("  5. correlation_matrix_with_pvalues.txt")

# ============================================================================
# CELL 19: Final Summary and Conclusions
# ============================================================================

print("\n" + "=" * 80)
print(" ~~~~ DETAILED ANALYSIS COMPLETE WITH FINAL SUMMARY ~~~ ")
print("=" * 80)

print(f"""
KEY FINDINGS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. PRIMARY CORRELATION
   âœ“ Moderate positive correlation between concentration and mortality
   âœ“ r = {r_primary:.4f}, p < 0.001, rÂ² = {r2_primary*100:.2f}%
   âœ“ Statistically significant and meaningful
   
2. STRENGTH INTERPRETATION
   â†’ {r2_primary*100:.2f}% of mortality variance explained by concentration
   â†’ {(1-r2_primary)*100:.2f}% explained by other factors (season, variants, etc.)
   
3. DIRECTION
   â†’ Positive: Higher concentration associated with higher mortality
   â†’ Matches biological expectation
   
4. MULTICOLLINEARITY ISSUE
   âš  Two concentration measures nearly identical (r={r_mult:.4f})
   â†’ Recommendation: Use only ONE in predictive models
   
5. SEASONALITY EFFECT
   â†’ Weak but detectable seasonal pattern (r={r_season_check:.4f})
   â†’ Suggests confounding by season/temperature
   
6. CAUSATION STATUS
   âœ— CORRELATION DOES NOT PROVE CAUSATION
   â†’ Likely explanation: Seasonal confounding
   â†’ Cannot rule out reverse causation (unlikely)
   â†’ Temporal lag analysis needed to establish precedence

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PRACTICAL IMPLICATIONS:

âœ“ Wastewater surveillance SHOULD be part of public health monitoring
âœ“ Moderate correlation justifies continued investment in surveillance
âœ“ Can serve as early warning indicator (especially if temporal lead confirmed)

âœ— Wastewater surveillance SHOULD NOT be used alone for policy decisions
âœ— Must be combined with other indicators
âœ— Causation cannot be inferred from this analysis

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

VISUALIZATIONS GENERATED:
  âœ“ Correlation matrix heatmap
  âœ“ Scatter plots (4 relationships examined)
  âœ“ Distribution histograms
  âœ“ Q-Q plots (normality verification)
  
STATISTICS CALCULATED:
  âœ“ Pearson correlations (primary, secondary, redundancy)
  âœ“ Spearman correlations (robustness check)
  âœ“ Variance Inflation Factors (multicollinearity)
  âœ“ Normality tests (Shapiro-Wilk)
  
REPORTS GENERATED:
  âœ“ Comprehensive text report
  âœ“ CSV files for spreadsheet review
  âœ“ P-values and detailed statistics

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

READY FOR NEXT PHASE:
  1. Share findings with stakeholders
  2. Conduct temporal lag analysis
  3. Develop predictive models
  4. Implement wastewater surveillance in public health system
  5. Combine with other data streams (cases, variants, hospitalizations)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("\nâœ… CORRELATION ANALYSIS NOTEBOOK COMPLETE!")
print("All analyses, visualizations, and reports have been generated.")
